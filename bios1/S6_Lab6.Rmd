---
title: "Model Diagnostics"
author: "BIOS 620"
date: "3/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Testing for significance of a multi-level categorical variable

## Example Dataset NHANES

```{r}
library(haven)
nhanes <- read_spss("NHANES_Lab4.sav")
head(nhanes)
```

## Create our factor variable

```{r}
edu_levels <- attributes(nhanes$Education)$labels
nhanes$Education_f <- factor(nhanes$Education,
    levels = edu_levels, labels = names(edu_levels))
table(nhanes$Education_f)
```

## Complete cases

```{r}
cc <- complete.cases(
    nhanes[, c("BPXSY1", "Male", "Exactage", "Education_f")]
)
nhanes_sub <- nhanes[cc, ]
head(nhanes_sub)
```

### Model 1

```{r}
fit1 <- lm(BPXSY1 ~ Male + Exactage, data = nhanes_sub)
summary(fit1)
```

### Model 2

```{r}
fit2 <- lm(BPXSY1 ~ Education_f + Male + Exactage, data = nhanes_sub)
summary(fit2)
```

### F-test between two models

Here we get the overall p-value for the Education variable. We need to
do this because Education has multiple categories.

```{r}
anova(fit1, fit2)
```

### Likelihood ratio test

We can also do the same with the likelihood ratio test function (`lrtest`) in
the `lmtest` package.

```{r}
library(lmtest)
lrtest(fit1, fit2)
```

## Sidenote: Calculate t-value

Let's manually calculate the t-value for the `Male` variable.

First let's look at the model summary:

```{r}
summary(fit1)
```

Now we obtain values from the summary output:

```{r}
( coef_table <- coef(summary(fit1)) )
stderr <- coef_table[2, 2]
male_coef <- coef_table[2, 1]
```

Calculate the t-value:

```{r}
male_coef / stderr
```

# Model Diagnostics

Now let's look at what model diagnostics we can run to ensure that our
assumptions for a linear regression are met. 

## Constant variance check (homoscedasticity)

### Example Dataset mtcars

Now let's look at our usual dataset. We use this dataset because we can
see an exaggerated effect in the plots of the residuals.

```{r}
data("mtcars")
head(mtcars)
```

```{r}
fit <- lm(mpg ~ wt, data = mtcars)
fit
```

Model summary output: 

```{r}
summary(fit)
```

Obtaining the fitted values and residual values:

```{r}
res <- residuals(fit)
yhat <- fitted(fit)
```

### Plotting fitted vs residuals

```{r}
plot(yhat, res)
```

### Scatter plot with smooth line

We should expect a straight line more or less across our plot.

```{r}
scatter.smooth(yhat, res, lpars = list(col = "red"))
```

## Normality of Residuals

To check for normality we can plot our distribution values (normal distribution)
versus our residuals in a Q-Q plot.

### Quantile-Quantile Plot

```{r}
qqnorm(res)
qqline(res, col = "steelblue", lwd = 2)
```

We can also visualize it using a histogram and overlaying it with a normal
curve.

```{r}
h <- hist(res, breaks = 20, col = "lightgray", xlab = "Residuals",
    freq = FALSE, main = "Histogram of Residuals")
xfit <- seq(min(res), max(res), length = 40)
yfit <- dnorm(xfit, mean = mean(res), sd = sd(res))
lines(xfit, yfit, col = "red", lwd = 2)
```

## Assessing linearity

```{r}
with(nhanes,
    scatter.smooth(Exactage, BPXSY1, lpars = list(col = "red", lwd = 3), span = 0.1)
)
```

### With a scatterplot?

A raw scatterplot won't help in general... but categorizing by age group
and plotting the means would.

```{r}
library(Hmisc)
nhanes$age_groups14 <- cut2(nhanes$Exactage, g = 14)
sbp_mean_groups <- tapply(nhanes$BPXSY1, nhanes$age_groups14, mean, na.rm = TRUE)
plot(sbp_mean_groups)
```

### What about BMI and Age?

```{r}
bmi_mean_groups <- tapply(nhanes$BMXBMI, nhanes$age_groups14, mean, na.rm = TRUE)
plot(bmi_mean_groups)
```

# Lab 6 (Analyze HELP RCT data as observational study)

# Hypothesis

```
HOMELESS and drink amount are structurally related.
```

* Outcome: i1 (\#of drinks in past 30 days)
* Study variable: HOMELESS
* Confounders: AGE, FEMALE, RACEGRP

## For the unadjusted analysis

* Appropriately summarize the outcome and study variable
* Use appropriate statistical method to assess the relationship between study
variable and the outcome (ideally linear regression to compare with adjusted
analysis)


## For the adjusted analysis:

* Use linear regression with study variable as independent variable and outcome
as dependent variable, controlling the confounders.
* Perform residual analysis for normality check and equal variance check.
